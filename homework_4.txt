1. Расскажите, как работает регуляризация в решающих деревьях, какие параметры мы штрафуем в данных алгоритмах?

Деревья легко переобучаются и процесс ветвления надо в какой-то момент останавливать - штрафовать.
Для этого есть разные параметры, обычно используются все сразу:
- ограничение по максимальной глубине дерева;
- ограничение на минимальное количество объектов в листе;
- ограничение на максимальное количество листьев в дереве;
- требование, чтобы функционал качества Branch при делении текущей подвыборки на две улучшался не менее чем на s процентов.
Делать это можно на разных этапах работы алгоритма, что не меняет сути, но имеет разные устоявшиеся названия:
- можно проверять критерии прямо во время построения дерева, такой способ называется pre-pruning или early stopping;
- а можно построить дерево жадно без ограничений, а затем провести стрижку (pruning), то есть удалить некоторые вершины из дерева так, 
чтобы итоговое качество упало не сильно, но дерево начало подходить под условия регуляризации. 


2. По какому принципу рассчитывается "важность признака (feature_importance)" в ансамблях деревьев?

Важность функции – техника присваивания очков полезности зависимым переменным – Предикторам (Predictor Variables) в зависимости от того, 
насколько они способны спрогнозировать Целевую переменную (Target Variable). Оценка важности играет важную роль в прогнозном моделировании, 
в том числе обеспечивает понимание данных, модели и создает предпосылки для Понижения размерности (Dimensionality Reduction) и отбора Признаков (Feature), 
которые могут повысить эффективность и действенность модели. 
Значения признаков предоставляются специальным атрибутом feature_importances_и вычисляются как среднее и среднеквадратическое отклонение в каждом дереве.